{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-2c3fe305963c>:35: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  df['like_dislike'] = df[['likes', 'dislikes']].apply(lambda row: row['likes'] / np.sum([row['likes'], row['dislikes']]), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>publish_hour</th>\n",
       "      <th>like_dislike</th>\n",
       "      <th>anti_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Malika LePen : Femme de Gauche - Trailer</td>\n",
       "      <td>Le Raptor Dissident</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-11-13T17:32:55.000Z</td>\n",
       "      <td>Raptor Dissident Expliquez cette merde</td>\n",
       "      <td>212702</td>\n",
       "      <td>29282</td>\n",
       "      <td>1108</td>\n",
       "      <td>3817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dimanche.\\n18h30.\\nSoyez présents vidéo plus r...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.963541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...</td>\n",
       "      <td>Le Labo</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-11-12T15:00:02.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>432721</td>\n",
       "      <td>14053</td>\n",
       "      <td>576</td>\n",
       "      <td>1161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Le jeu société: https://goo.gl/hhG1Ta\\n\\nGagne...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.960626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...</td>\n",
       "      <td>Daniil le Russe</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-11-13T17:00:38.000Z</td>\n",
       "      <td>cartoon pokémon école ours мультфильм</td>\n",
       "      <td>482153</td>\n",
       "      <td>76203</td>\n",
       "      <td>477</td>\n",
       "      <td>9580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Une nouvelle dose dessins animés français russ...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.993779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>PAPY GRENIER - METAL GEAR SOLID</td>\n",
       "      <td>Joueur Du Grenier</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-11-12T17:00:02.000Z</td>\n",
       "      <td>Papy grenier Metal Gear Solid PS1 Tirage d'ore...</td>\n",
       "      <td>925222</td>\n",
       "      <td>85016</td>\n",
       "      <td>550</td>\n",
       "      <td>4303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nouvel ,épisode Papy Grenier ! Ce mois-ci part...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...</td>\n",
       "      <td>Aurelien Fontenoy</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11-13T16:30:03.000Z</td>\n",
       "      <td>vélo vtt bmx freestyle bike mtb dirt trottinet...</td>\n",
       "      <td>141695</td>\n",
       "      <td>8091</td>\n",
       "      <td>72</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sauts plus 4 mètres haut trampoline park / air...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.991180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trending_date                                              title  \\\n",
       "0      17.14.11           Malika LePen : Femme de Gauche - Trailer   \n",
       "1      17.14.11  LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...   \n",
       "2      17.14.11  DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...   \n",
       "3      17.14.11                    PAPY GRENIER - METAL GEAR SOLID   \n",
       "4      17.14.11  QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...   \n",
       "\n",
       "         channel_title  category_id              publish_time  \\\n",
       "0  Le Raptor Dissident            9  2017-11-13T17:32:55.000Z   \n",
       "1              Le Labo            9  2017-11-12T15:00:02.000Z   \n",
       "2      Daniil le Russe            8  2017-11-13T17:00:38.000Z   \n",
       "3    Joueur Du Grenier            6  2017-11-12T17:00:02.000Z   \n",
       "4    Aurelien Fontenoy            4  2017-11-13T16:30:03.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0             Raptor Dissident Expliquez cette merde  212702  29282      1108   \n",
       "1                                             [none]  432721  14053       576   \n",
       "2              cartoon pokémon école ours мультфильм  482153  76203       477   \n",
       "3  Papy grenier Metal Gear Solid PS1 Tirage d'ore...  925222  85016       550   \n",
       "4  vélo vtt bmx freestyle bike mtb dirt trottinet...  141695   8091        72   \n",
       "\n",
       "   comment_count  comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0           3817                  0                 0                       0   \n",
       "1           1161                  0                 0                       0   \n",
       "2           9580                  0                 0                       0   \n",
       "3           4303                  0                 0                       0   \n",
       "4            481                  0                 0                       0   \n",
       "\n",
       "                                         description  publish_hour  \\\n",
       "0  Dimanche.\\n18h30.\\nSoyez présents vidéo plus r...            17   \n",
       "1  Le jeu société: https://goo.gl/hhG1Ta\\n\\nGagne...            15   \n",
       "2  Une nouvelle dose dessins animés français russ...            17   \n",
       "3  Nouvel ,épisode Papy Grenier ! Ce mois-ci part...            17   \n",
       "4  Sauts plus 4 mètres haut trampoline park / air...            16   \n",
       "\n",
       "   like_dislike  anti_participation  \n",
       "0      0.963541                   0  \n",
       "1      0.960626                   0  \n",
       "2      0.993779                   0  \n",
       "3      0.993572                   0  \n",
       "4      0.991180                   0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "lower = False\n",
    "#feature = 'title'\n",
    "feature = 'tags'\n",
    "#feature = 'description'\n",
    "#region, language = 'US', 'english'   # \n",
    "#region, language = 'KR', 'korean'    # doesn't work\n",
    "#region, language = 'MX', 'spanish'   # doesn't work\n",
    "#region, language = 'CA', 'english'   #\n",
    "#region, language = 'DE', 'german'    #\n",
    "region, language = 'FR', 'french'    #\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "def load_region_data(region: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv('./archive/{}videos.csv'.format(region))\n",
    "\n",
    "    # Drop unused columns\n",
    "    df = df.drop(['thumbnail_link', 'video_id'], axis=1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Enrich data\n",
    "    df['publish_hour'] = pd.to_datetime(df['publish_time']).dt.hour\n",
    "    df['comments_disabled'] = df['comments_disabled'].apply(lambda row: 0 if row == False else 1)\n",
    "    df['ratings_disabled'] = df['ratings_disabled'].apply(lambda row: 0 if row == False else 1)\n",
    "    df['video_error_or_removed'] = df['video_error_or_removed'].apply(lambda row: 0 if row == False else 1)\n",
    "    df['like_dislike'] = df[['likes', 'dislikes']].apply(lambda row: row['likes'] / np.sum([row['likes'], row['dislikes']]), axis=1)\n",
    "    df['tags'] = df['tags'].apply(lambda row: ' '.join( i.strip('\"\"') for i in row.split('|') ))\n",
    "    df['anti_participation'] = df[['comments_disabled', 'ratings_disabled']].apply(lambda row: row.sum(), axis=1)\n",
    "\n",
    "    # Transform category_id to label\n",
    "    category_le = sk.preprocessing.LabelEncoder()\n",
    "    category_le.fit(df['category_id'])\n",
    "    df['category_id'] = category_le.transform(df['category_id'])\n",
    "\n",
    "    # Load stopwords\n",
    "    try:\n",
    "        stop_words = set(nltk.corpus.stopwords.words(language))\n",
    "    except Exception:\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(nltk.corpus.stopwords.words(language))\n",
    "    \n",
    "    # Drop stopwords\n",
    "    df['tags'] = df['tags'].apply(lambda row: ' '.join(word for word in row.split() if word not in stop_words))\n",
    "    df['description'] = df['description'].apply(lambda row: ' '.join(word for word in row.split() if word not in stop_words))\n",
    "    \n",
    "    return df, len(category_le.classes_)\n",
    "\n",
    "df, num_classes = load_region_data(region)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37812, 100), (37812, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_sequences(x):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=lower)\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    _sequences = tokenizer.texts_to_sequences(x)\n",
    "    maxlen = max(len(_seq) for _seq in _sequences)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    _xtr = tf.keras.preprocessing.sequence.pad_sequences(_sequences, maxlen, padding='post')\n",
    "    \n",
    "    return np.array(_xtr), maxlen, vocab_size\n",
    "\n",
    "if feature == 'tags':\n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['tags'].to_numpy())\n",
    "elif feature == 'description':\n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['description'].to_numpy())\n",
    "elif feature == 'title': \n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['title'].to_numpy())\n",
    "\n",
    "Y = df['category_id'].to_numpy().reshape((-1,1))\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 75)           5900100   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 75)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 93, 64)            38464     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 88, 32)            12320     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 85, 16)            2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 85, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 85, 8)             136       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 680)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                12258     \n",
      "=================================================================\n",
      "Total params: 5,965,342\n",
      "Trainable params: 5,965,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation = 'softmax'\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input(shape=(maxlen,)))\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 75))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=8, activation=activation))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=6, activation=activation))\n",
    "model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=4, activation=activation))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc/nyu/ml/proj/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532/532 [==============================] - 13s 24ms/step - loss: 2.3068 - categorical_accuracy: 0.2498 - val_loss: 2.2870 - val_categorical_accuracy: 0.2515\n",
      "532/532 [==============================] - 13s 24ms/step - loss: 2.1031 - categorical_accuracy: 0.2955 - val_loss: 1.7953 - val_categorical_accuracy: 0.4008\n",
      "158/532 [=======>......................] - ETA: 8s - loss: 1.7217 - categorical_accuracy: 0.4047"
     ]
    }
   ],
   "source": [
    "# Initialize history variables\n",
    "loss_history, accuracy_history = [[],[]], [[],[]]\n",
    "final_accuracy = -1.\n",
    "\n",
    "to_categorical = tf.keras.utils.to_categorical\n",
    "\n",
    "# Kfold cross validation\n",
    "skf = sk.model_selection.StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    # Get train and test fold\n",
    "    xtrain, xval = X[train_index], X[val_index]\n",
    "    \n",
    "    # We need to convert the Y to a categorical type in order for the \n",
    "    # multi-classifier to train and validate properly\n",
    "    ytrain = to_categorical(Y[train_index], num_classes=num_classes)\n",
    "    yval = to_categorical(Y[val_index], num_classes=num_classes)\n",
    "    \n",
    "    # Train and validate\n",
    "    history = model.fit(xtrain, ytrain, validation_data=(xval, yval), epochs=1, batch_size=64)\n",
    "    \n",
    "    # Add values to training history\n",
    "    loss_history[0].extend(history.history['val_loss'])\n",
    "    loss_history[1].extend(history.history['loss'])\n",
    "    accuracy_history[0].extend(history.history['val_categorical_accuracy'])\n",
    "    accuracy_history[1].extend(history.history['categorical_accuracy'])\n",
    "    final_accuracy = history.history['val_categorical_accuracy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize history\n",
    "# Plot history: Loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_history[0], label='validation')\n",
    "ax.plot(loss_history[1], label='train')\n",
    "ax.set(title='Validation loss history', xlabel='No. split', ylabel='Loss value')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "# Plot history: Accuracy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(accuracy_history[0], label='validation')\n",
    "ax.plot(accuracy_history[1], label='train')\n",
    "ax.set(title='Validation accuracy history', xlabel='No. split', ylabel='Accuracy value')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('.models/', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save('.models/model-{region}-{feature}-{accuracy:.2f}.h5'.format(region=region, feature=feature, accuracy=final_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
