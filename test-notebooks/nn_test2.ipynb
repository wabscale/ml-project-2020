{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "df = pd.read_parquet('./frame.parquet.gzip')\n",
    "xdf = df[['title', 'tags', 'description', 'publish_hour', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed', 'channel_title']]\n",
    "ydf = df[['category_id']]\n",
    "Xtr, Xts, ytr, yts = train_test_split(xdf, ydf, shuffle=True, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sequences(x):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    _sequences = tokenizer.texts_to_sequences(x)\n",
    "    maxlen = max(len(_seq) for _seq in _sequences)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    _xtr = tf.keras.preprocessing.sequence.pad_sequences(_sequences, maxlen, padding='post')\n",
    "    \n",
    "    return _xtr, maxlen, vocab_size\n",
    "\n",
    "def create_text_channel(maxlen, vocab_size):\n",
    "    input_ = tf.keras.layers.Input(shape=(maxlen,))\n",
    "    embedding = tf.keras.layers.Embedding(vocab_size, 1028)(input_)\n",
    "    conv = tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='softmax')(embedding)\n",
    "    drop = tf.keras.layers.Dropout(0.05)(conv)\n",
    "    pool = tf.keras.layers.MaxPooling1D(pool_size=2)(drop)\n",
    "    flat = tf.keras.layers.Flatten()(pool)\n",
    "    \n",
    "    return input_, flat\n",
    "\n",
    "def create_numerical_channel(shape=(3,)):\n",
    "    input_ = tf.keras.layers.Input(shape=shape)\n",
    "    dense = tf.keras.layers.Dense(8, activation='softmax')(input_)\n",
    "    dense = tf.keras.layers.Dense(6, activation='softmax')(input_)\n",
    "    #conv = tf.keras.layers.Conv1D(filters=10, kernel_size=4, activation='softmax')(dense)\n",
    "    drop = tf.keras.layers.Dropout(0.05)(dense)\n",
    "    flat = tf.keras.layers.Flatten()(drop)\n",
    "    \n",
    "    return input_, drop\n",
    "\n",
    "\n",
    "def create_model(maxlen_vocabsz, tchannels=3, nchannels=3):\n",
    "    inputs = []\n",
    "    merge = []\n",
    "    \n",
    "    for maxlen, vocab_size in maxlen_vocabsz:\n",
    "        for _ in range(tchannels):\n",
    "            input_, flat = create_text_channel(maxlen, vocab_size)\n",
    "            inputs.append(input_)\n",
    "            merge.append(flat)\n",
    "            \n",
    "    for _ in range(nchannels):\n",
    "        input_, flat = create_numerical_channel(shape=(3,))\n",
    "        inputs.append(input_)\n",
    "        merge.append(flat)\n",
    "    \n",
    "    merged = tf.keras.layers.Concatenate()(merge)\n",
    "    dense = tf.keras.layers.Dense(10, activation='relu')(merged)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='relu')(dense)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_vocabsz = []\n",
    "Xtrain = []\n",
    "\n",
    "tchannels = 1\n",
    "for feat in ['title', 'tags', 'description', 'channel_title']:\n",
    "    _xtr, _maxlen, _vocab_size = convert_to_sequences(Xtr[feat].to_list())\n",
    "    maxlen_vocabsz.append((_maxlen, _vocab_size))\n",
    "    for _ in range(tchannels):\n",
    "        Xtrain.append(np.array(_xtr))\n",
    "\n",
    "nfeats = ['publish_hour', 'comments_disabled', 'ratings_disabled']\n",
    "nchannels = 3\n",
    "for _ in range(nchannels):\n",
    "    Xtrain.append(Xtr[nfeats].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1691/1691 [==============================] - 53s 31ms/step - loss: -55.5922 - accuracy: 0.2444\n",
      "Epoch 2/3\n",
      "1691/1691 [==============================] - 53s 31ms/step - loss: -55.6464 - accuracy: 0.2445\n",
      "Epoch 3/3\n",
      "1691/1691 [==============================] - 53s 31ms/step - loss: -55.6465 - accuracy: 0.2445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56299e8850>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(maxlen_vocabsz, tchannels=tchannels, nchannels=nchannels)\n",
    "model.fit(Xtrain, ytr.to_numpy(), epochs=3, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
