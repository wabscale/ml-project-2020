{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_parquet('./frame.parquet.gzip')\n",
    "\n",
    "xdf = df[['title', 'tags', 'publish_time', 'anti_participation', 'video_error_or_removed']]\n",
    "ydf = df[['category_id']]\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(xdf, ydf, shuffle=True, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sequences(x):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    _sequences = tokenizer.texts_to_sequences(x)\n",
    "    maxlen = max(len(_seq) for _seq in _sequences)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    _xtr = pad_sequences(_sequences, maxlen, padding='post')\n",
    "    \n",
    "    return _xtr, maxlen, vocab_size\n",
    "\n",
    "def create_input_channel(maxlen, vocab_size):\n",
    "    input_ = Input(shape=(maxlen,))\n",
    "    embedding = Embedding(vocab_size, 100)(input_)\n",
    "    conv = Conv1D(filters=32, kernel_size=4, activation='softmax')(embedding)\n",
    "    drop = Dropout(0.5)(conv)\n",
    "    pool = MaxPooling1D(pool_size=2)(drop)\n",
    "    flat = Flatten()(pool)\n",
    "    \n",
    "    return input_, flat\n",
    "\n",
    "Xtr1, maxlen1, vocab_size1 = convert_to_sequences(Xtr['title'].to_list())\n",
    "Xtr2, maxlen2, vocab_size2 = convert_to_sequences(Xtr['tags'].to_list())\n",
    "\n",
    "input11, flat11 = create_input_channel(maxlen1, vocab_size1)\n",
    "input12, flat12 = create_input_channel(maxlen1, vocab_size1)\n",
    "input13, flat13 = create_input_channel(maxlen1, vocab_size1)\n",
    "\n",
    "input21, flat21 = create_input_channel(maxlen2, vocab_size2)\n",
    "input22, flat22 = create_input_channel(maxlen2, vocab_size2)\n",
    "input23, flat23 = create_input_channel(maxlen2, vocab_size2)\n",
    "\n",
    "merged = Concatenate()([\n",
    "    flat11, flat12, flat13, \n",
    "    flat21, flat22, flat23,\n",
    "])\n",
    "\n",
    "dense = Dense(10, activation='softmax')(merged)\n",
    "outputs = Dense(1, activation='softmax')(dense)\n",
    "model = Model(inputs=[input11, input12, input13, input21, input22, input23], outputs=outputs)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 2/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 3/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 4/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 5/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4248 - accuracy: 0.2462\n",
      "Epoch 6/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 7/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 8/10\n",
      "1691/1691 [==============================] - 67s 39ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 9/10\n",
      "1691/1691 [==============================] - 68s 40ms/step - loss: -55.4249 - accuracy: 0.2462\n",
      "Epoch 10/10\n",
      "1691/1691 [==============================] - 70s 41ms/step - loss: -55.4249 - accuracy: 0.2462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08c2da3250>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xtr1,Xtr1,Xtr1, Xtr2,Xtr2,Xtr2], ytr.to_numpy(), epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
