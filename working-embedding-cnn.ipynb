{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-0f986b5e07bc>:32: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  df['like_dislike'] = df[['likes', 'dislikes']].apply(lambda row: row['likes'] / np.sum([row['likes'], row['dislikes']]), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>publish_hour</th>\n",
       "      <th>like_dislike</th>\n",
       "      <th>anti_participation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.950970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency last week t...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One year presidential election, John Oliver di...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.940521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman rudy mancuso king bach racist ...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.964729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett link gmm good mythical morning rhett lin...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Today find Link Nickelback amateur secret Nick...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.938550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan higa higatv nigahiga dare idy rhpc dares ...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I know since show, we're back might best episo...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.985181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trending_date                                              title  \\\n",
       "0      17.14.11                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1      17.14.11  The Trump Presidency: Last Week Tonight with J...   \n",
       "2      17.14.11  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3      17.14.11                   Nickelback Lyrics: Real or Fake?   \n",
       "4      17.14.11                           I Dare You: GOING BALD!?   \n",
       "\n",
       "           channel_title  category_id              publish_time  \\\n",
       "0           CaseyNeistat            7  2017-11-13T17:13:01.000Z   \n",
       "1        LastWeekTonight            9  2017-11-13T07:30:00.000Z   \n",
       "2           Rudy Mancuso            8  2017-11-12T19:05:24.000Z   \n",
       "3  Good Mythical Morning            9  2017-11-13T11:00:04.000Z   \n",
       "4               nigahiga            9  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  last week tonight trump presidency last week t...  2418783   97185   \n",
       "2  racist superman rudy mancuso king bach racist ...  3191434  146033   \n",
       "3  rhett link gmm good mythical morning rhett lin...   343168   10172   \n",
       "4  ryan higa higatv nigahiga dare idy rhpc dares ...  2095731  132235   \n",
       "\n",
       "   dislikes  comment_count  comments_disabled  ratings_disabled  \\\n",
       "0      2966          15954                  0                 0   \n",
       "1      6146          12703                  0                 0   \n",
       "2      5339           8181                  0                 0   \n",
       "3       666           2146                  0                 0   \n",
       "4      1989          17518                  0                 0   \n",
       "\n",
       "   video_error_or_removed                                        description  \\\n",
       "0                       0  SHANTELL'S CHANNEL - https://www.youtube.com/s...   \n",
       "1                       0  One year presidential election, John Oliver di...   \n",
       "2                       0  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...   \n",
       "3                       0  Today find Link Nickelback amateur secret Nick...   \n",
       "4                       0  I know since show, we're back might best episo...   \n",
       "\n",
       "   publish_hour  like_dislike  anti_participation  \n",
       "0            17      0.950970                   0  \n",
       "1             7      0.940521                   0  \n",
       "2            19      0.964729                   0  \n",
       "3            11      0.938550                   0  \n",
       "4            18      0.985181                   0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk.corpus\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "feature = 'tags'\n",
    "language = 'US', 'english'\n",
    "#language = 'KR', 'korean'\n",
    "#language = 'MX', 'spanish'\n",
    "#language = 'CA', 'english'\n",
    "#language = 'DE', 'german'\n",
    "#lanugage = 'FR', 'french'\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "df = pd.read_csv('./archive/{}videos.csv'.format(language[0]))\n",
    "categories = json.load(open('./archive/{}_category_id.json'.format(language[0]), 'rb'))\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(['thumbnail_link', 'video_id'], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "# Enrich data\n",
    "df['publish_hour'] = pd.to_datetime(df['publish_time']).dt.hour\n",
    "df['comments_disabled'] = df['comments_disabled'].apply(lambda row: 0 if row == False else 1)\n",
    "df['ratings_disabled'] = df['ratings_disabled'].apply(lambda row: 0 if row == False else 1)\n",
    "df['video_error_or_removed'] = df['video_error_or_removed'].apply(lambda row: 0 if row == False else 1)\n",
    "df['like_dislike'] = df[['likes', 'dislikes']].apply(lambda row: row['likes'] / np.sum([row['likes'], row['dislikes']]), axis=1)\n",
    "df['tags'] = df['tags'].apply(lambda row: ' '.join( i.strip('\"\"') for i in row.split('|') ))\n",
    "df['anti_participation'] = df[['comments_disabled', 'ratings_disabled']].apply(lambda row: row.sum(), axis=1)\n",
    "\n",
    "#category_name_mapping = {}\n",
    "#for item in categories['items']:\n",
    "#    category_name_mapping[int(item['id'])] = item['snippet']['title']\n",
    "#df['category_name'] = df['category_id'].apply(lambda row: category_name_mapping[int(row)])\n",
    "\n",
    "category_le = sk.preprocessing.LabelEncoder()\n",
    "category_le.fit(df['category_id'])\n",
    "df['category_id'] = category_le.transform(df['category_id'])\n",
    "\n",
    "# Take out stop words\n",
    "try:\n",
    "    stop_words = set(nltk.corpus.stopwords.words(language[1]))\n",
    "except Exception:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(nltk.corpus.stopwords.words(language[1]))\n",
    "df['tags'] = df['tags'].apply(lambda row: ' '.join(word for word in row.split() if word not in stop_words))\n",
    "df['description'] = df['description'].apply(lambda row: ' '.join(word for word in row.split() if word not in stop_words))\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40379, 91), (40379, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_sequences(x):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    _sequences = tokenizer.texts_to_sequences(x)\n",
    "    maxlen = max(len(_seq) for _seq in _sequences)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    _xtr = tf.keras.preprocessing.sequence.pad_sequences(_sequences, maxlen, padding='post')\n",
    "    \n",
    "    return np.array(_xtr), maxlen, vocab_size\n",
    "\n",
    "if feature == 'tags':\n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['tags'].to_numpy())\n",
    "elif feature == 'description':\n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['description'].to_numpy())\n",
    "elif feature == 'title': \n",
    "    X, maxlen, vocab_size = convert_to_sequences(df['title'].to_numpy())\n",
    "\n",
    "Y = df['category_id'].to_numpy().reshape((-1,1))\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 91, 75)            2303025   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 91, 75)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 84, 64)            38464     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 79, 32)            12320     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 76, 16)            2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 76, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 76, 8)             136       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 608)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                9744      \n",
      "=================================================================\n",
      "Total params: 2,365,753\n",
      "Trainable params: 2,365,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation = 'softmax'\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input(shape=(maxlen,)))\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 75))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=8, activation=activation))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=6, activation=activation))\n",
    "model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=4, activation=activation))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(len(category_le.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 6s 10ms/step - loss: 2.2837 - categorical_accuracy: 0.2639 - val_loss: 1.7671 - val_categorical_accuracy: 0.3997\n",
      "568/568 [==============================] - 5s 10ms/step - loss: 1.3205 - categorical_accuracy: 0.5656 - val_loss: 0.9385 - val_categorical_accuracy: 0.6986\n",
      "475/568 [========================>.....] - ETA: 0s - loss: 0.8395 - categorical_accuracy: 0.7272"
     ]
    }
   ],
   "source": [
    "loss_history, accuracy_history = [[],[]], [[],[]]\n",
    "final_accuracy = -1.\n",
    "\n",
    "# Kfold \n",
    "skf = sk.model_selection.StratifiedKFold(n_splits=10, shuffle=True)\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    xtrain, xval = X[train_index], X[val_index]\n",
    "    ytrain, yval = tf.keras.utils.to_categorical(Y[train_index]), tf.keras.utils.to_categorical(Y[val_index])\n",
    "    \n",
    "    history = model.fit(xtrain, ytrain, validation_data=(xval, yval), epochs=1, batch_size=64)\n",
    "    \n",
    "    loss_history[0].extend(history.history['val_loss'])\n",
    "    loss_history[1].extend(history.history['loss'])\n",
    "    accuracy_history[0].extend(history.history['val_categorical_accuracy'])\n",
    "    accuracy_history[1].extend(history.history['categorical_accuracy'])\n",
    "    \n",
    "    final_accuracy = history.history['val_categorical_accuracy'][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize history\n",
    "# Plot history: Loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_history[0], label='validation')\n",
    "ax.plot(loss_history[1], label='train')\n",
    "ax.set(title='Validation loss history', xlabel='No. split', ylabel='Loss value')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "# Plot history: Accuracy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(accuracy_history[0], label='validation')\n",
    "ax.plot(accuracy_history[1], label='train')\n",
    "ax.set(title='Validation accuracy history', xlabel='No. split', ylabel='Accuracy value')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-{lang}-{feature}-{accuracy}.h5'.format(lang=language[1], feature=feature, accuracy=final_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
